{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVQQ6iYqh877",
        "outputId": "2b67672c-87d9-4f60-f448-e1e1dd7785e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Define the list of links to scrape\n",
        "links = ['https://www.nike.com/in/', 'https://www.adidas.co.in', 'https://us.puma.com/us/en', 'https://www.skechers.com', 'https://columbiasportswear.co.in','https://www.woodlandworldwide.com']\n",
        "\n",
        "# Create an empty list to store the content of each link\n",
        "content = []\n",
        "\n",
        "# Iterate over the list of links\n",
        "for link in links:\n",
        "  # Make a GET request to the link\n",
        "  response = requests.get(link)\n",
        "\n",
        "  # Parse the HTML content using BeautifulSoup\n",
        "  soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "  # Get the title of the page\n",
        "  title = soup.title.text\n",
        "\n",
        "  # Get the body of the page\n",
        "  body = soup.body\n",
        "\n",
        "  # Add the title and body to the content list\n",
        "  content.append((title, body))\n",
        "\n",
        "# Print the content of each link\n",
        "for title, body in content:\n",
        "  print(f'Title: {title}')\n",
        "  print(f'Body: {body}')"
      ],
      "metadata": {
        "id": "g79moDFblEp5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}